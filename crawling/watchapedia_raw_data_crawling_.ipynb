{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84763765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager # 자동으로 크롬드라이버(가상브라우저) 파일을 다운로드해주는 라이브러리\n",
    "from selenium.webdriver.chrome.service import Service # 다운로드된 크롬드라이버 파일을 연결하기 위해 활용\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a598c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_users = pd.DataFrame(columns = ['제목','링크','평점','유저 이름'])\n",
    "data_df = pd.DataFrame(columns = ['제목','링크','평점','유저 이름'])\n",
    "\n",
    "service = Service(executable_path=ChromeDriverManager().install()) \n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get(\"https://pedia.watcha.com/ko-KR/staffmades/267\") \n",
    "time.sleep(3)\n",
    "\n",
    "# 아래 코드가 특정 웹페이지에서 Selenium을 활용해 스크롤 다운하는 코드입니다.\n",
    "# 가장 아래까지 스크롤 다운 후 매번 0.8초씩 로딩을 기다린 후 스크롤 다운을 마지막까지 진행합니다.\n",
    "while True:\n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if newHeight == lastHeight:\n",
    "         break\n",
    "\n",
    "# 광고 지우기\n",
    "close_button = '/html/body/div/div/div[2]/div/div/div/button/span'\n",
    "driver.find_element_by_xpath(close_button).click()\n",
    "\n",
    "# Beautifulsoup으로 영화 데이터\n",
    "movie_name = []\n",
    "url = driver.current_url\n",
    "movie_url = 'https://pedia.watcha.com'\n",
    "movie_link = []\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "movies = soup.find_all('li',{'class':'css-8y23cj'})\n",
    "\n",
    "for movie in movies:\n",
    "    movie_name.append(movie.find('a').get('title'))\n",
    "    movie_link.append(movie_url + movie.find('a').get('href'))\n",
    "\n",
    "# 드라이버 끝내기\n",
    "driver.close()\n",
    "driver.quit()\n",
    "\n",
    "df_movie = pd.DataFrame(zip(movie_name,movie_link),columns=['왓챠피디아 평점 TOP 영화','링크'])\n",
    "\n",
    "df_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82b1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [제목, 링크, 평점, 유저 이름]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path=ChromeDriverManager().install()) \n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# 영화 각각 링크로 들어가기\n",
    "for i in range (0, 299):\n",
    "    driver.get(df_movie['링크'][0]) #여기서 반복문\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 광고 지우기\n",
    "    close_button = '/html/body/div/div/div[2]/div/div/div/button/span'\n",
    "    driver.find_element_by_xpath(close_button).click()\n",
    "    \n",
    "    # 코멘트 더보기 클릭\n",
    "    time.sleep(SCROLL_PAUSE)\n",
    "    comment_button_xpath = '//*[@id=\"root\"]/div/div[1]/section/div/div[2]/div/div/div/div[1]/div[1]/div/div/section[5]/div[1]/div/header/div/div/a'\n",
    "    driver.find_element_by_xpath(comment_button_xpath).click()\n",
    "    \n",
    "    # 스크롤 내리기 (4초; 생각보다 코멘트 로딩이 느림 / 스크롤이 너무 빨리 내려가면 더이상 안 내려가는 오류발생)\n",
    "    while True:\n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(4)\n",
    "    newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if newHeight == lastHeight:\n",
    "         break\n",
    "    \n",
    "    # Beautifulsoup으로 유저 데이터\n",
    "    user_name = []\n",
    "    review_url = driver.current_url\n",
    "    movie_url = 'https://pedia.watcha.com'\n",
    "    user_link = []\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    users = soup.find_all('div',{'class':'css-1cvf9dk'})\n",
    "\n",
    "    for user in users:\n",
    "        user_name.append(user.find('a').get('title'))\n",
    "        user_link.append(movie_url + user.find('a').get('href'))\n",
    "\n",
    "    df_user = pd.DataFrame(zip(user_name,user_link),columns=['유저','유저 링크'])\n",
    "    \n",
    "    # 유저 데이터 행 구하기; 링크 index용\n",
    "    num_user = df_user.shape[0]\n",
    "    \n",
    "    # 유저 링크 하나씩 들어가기\n",
    "    for j in range (1, num_user):\n",
    "        user_page = df_user['유저 링크'][j]\n",
    "        user_movie = ''\n",
    "        ratings_url = '/contents/movies/ratings'\n",
    "        user_movie = user_page+ratings_url\n",
    "        driver.get(user_movie)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 광고 지우기\n",
    "        close_button = '/html/body/div/div/div[2]/div/div/div/button/span'\n",
    "        driver.find_element_by_xpath(close_button).click()\n",
    "\n",
    "        # 스크롤 내리기\n",
    "        while True:\n",
    "            lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(1)\n",
    "            newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if newHeight == lastHeight:\n",
    "                 break\n",
    "\n",
    "        # Beautifulsoup으로 영화 데이터\n",
    "        movie_name = []\n",
    "        movie_url = driver.current_url\n",
    "        movie_link = []\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        movies = soup.find_all('li',{'class':'css-8y23cj'})\n",
    "\n",
    "        for movie in movies:\n",
    "            movie_name.append(movie.find('a').get('title'))\n",
    "            movie_link.append(movie_url + movie.find('a').get('href'))\n",
    "\n",
    "        df_movie_2 = pd.DataFrame(data = [movie_name, movie_link]).T\n",
    "\n",
    "        # 위 데이터 프레임 행 = 그 페이지에 있는 영화 개수\n",
    "        num = df_movie_2.shape[0]\n",
    "\n",
    "        # Beautifulsoup으로 영화 데이터\n",
    "\n",
    "        movie_name = []\n",
    "        movie_link = []\n",
    "        movie_score = []\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        movies = soup.find_all('li',{'class':'css-8y23cj'})\n",
    "\n",
    "        for movie in movies:\n",
    "            movie_name.append(movie.find('a').get('title'))\n",
    "            movie_link.append(movie_url + movie.find('a').get('href'))\n",
    "        for k in range (1,num):\n",
    "            item_score = driver.find_element_by_xpath(f'/html/body/div[1]/div/div[1]/section/section/div[1]/section/div[1]/div/ul/li[{k}]/a/div[2]/div[2]')\n",
    "            movie_score.append(item_score.text)\n",
    "\n",
    "        df_movie_2 = pd.DataFrame(data = [movie_name, movie_link,movie_score]).T\n",
    "\n",
    "        data_df_new = pd.DataFrame(zip(movie_name,movie_link,movie_score),columns=['제목','링크','평점'])\n",
    "        data_df_new['유저 이름'] = df_user.iloc[j]['유저']\n",
    "        data_df_new\n",
    "        \n",
    "        data_df_users = data_df_users.append(data_df_new)\n",
    "        data_df_users\n",
    "        \n",
    "    data_df = data_df.append(data_df_users)\n",
    "    data_df\n",
    "\n",
    "# 드라이버 끝내기\n",
    "driver.close()\n",
    "driver.quit()\n",
    "    \n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b8567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01962b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5625c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06aae26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5fa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24b6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708e5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
